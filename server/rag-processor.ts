import OpenAI from 'openai';
import Anthropic from '@anthropic-ai/sdk';
import { storage } from './storage';
import { DocumentChunk, smartChunking } from './document-chunking';
import { createClient } from '@supabase/supabase-js';
import { logLlmUsage } from './llm';
import dotenv from 'dotenv';

// Carregar vari√°veis de ambiente
dotenv.config();

/**
 * Processa um documento, divide em chunks e cria embeddings
 */
export async function processDocumentForRAG(
  documentId: number,
  documentText: string,
  options: {
    sourceType?: string;
    documentType?: string;
    language?: 'pt' | 'en';
    documentName?: string;
    chunkSize?: number;
    overlapSize?: number;
  } = {}
): Promise<{
  chunks: DocumentChunk[];
  totalChunks: number;
  success: boolean;
  error?: string;
}> {
  try {
    const {
      sourceType = 'document',
      documentType = 'manual',
      language = 'pt',
      documentName = `Documento ${documentId}`,
      chunkSize = 1500,
      overlapSize = 150
    } = options;
    
    console.log(`Processando documento ${documentId} para RAG: ${documentName}`);
    
    if (!documentText || documentText.trim().length === 0) {
      return {
        chunks: [],
        totalChunks: 0,
        success: false,
        error: 'Documento vazio'
      };
    }
    
    // Dividir documento em chunks usando estrat√©gia inteligente
    const chunks = smartChunking(documentText, documentId, sourceType, documentType, {
      maxChunkSize: chunkSize,
      overlapSize: overlapSize,
      language,
      documentName
    });
    
    console.log(`Documento dividido em ${chunks.length} chunks`);
    
    // Salvar chunks no banco de dados
    for (const chunk of chunks) {
      try {
        // Criar embedding para o chunk
        const embedding = await createEmbedding(chunk.content);
        
        // Salvar o chunk com embedding
        await storage.createDocumentChunk({
          document_id: documentId,
          chunk_index: chunk.metadata.chunkIndex,
          content: chunk.content,
          content_hash: chunk.metadata.contentHash,
          source_type: sourceType,
          language: language,
          embedding: embedding || undefined
        });
      } catch (chunkError: any) {
        console.error(`Erro ao processar chunk ${chunk.metadata.chunkIndex}:`, chunkError);
        // Continuar para o pr√≥ximo chunk
      }
    }
    
    // Criar uma entrada na base de conhecimento (para fins de busca)
    await storage.createKnowledgeEntry({
      source_type: sourceType as any,
      source_id: documentId,
      content: documentText.substring(0, 1000) + (documentText.length > 1000 ? '...' : ''),
      language: language,
      metadata: JSON.stringify({
        documentName: documentName,
        documentType: documentType,
        chunkCount: chunks.length
      }),
      processed_at: new Date(),
      is_verified: true
    });
    
    return {
      chunks,
      totalChunks: chunks.length,
      success: true
    };
  } catch (error: any) {
    console.error('Erro ao processar documento para RAG:', error);
    return {
      chunks: [],
      totalChunks: 0,
      success: false,
      error: error.message
    };
  }
}

/**
 * Cria embeddings para um texto usando OpenAI
 */
export async function createEmbedding(text: string): Promise<number[] | null> {
  try {
    // Truncar o texto se for muito grande (limite API OpenAI)
    const truncatedText = text.length > 8000 ? text.substring(0, 8000) : text;
    
    // Obter configura√ß√£o LLM
    const llmConfig = await storage.getActiveLlmConfig();
    if (!llmConfig) {
      throw new Error('Nenhuma configura√ß√£o LLM ativa encontrada');
    }
    
    // Determinar qual modelo usar
    const apiKey = llmConfig.api_key || process.env.OPENAI_API_KEY;
    
    if (!apiKey) {
      throw new Error('API key n√£o dispon√≠vel para cria√ß√£o de embedding');
    }
    
    // Inicializar cliente OpenAI
    const openai = new OpenAI({ apiKey });
    
    const response = await openai.embeddings.create({
      model: "text-embedding-3-small",
      input: truncatedText,
      encoding_format: "float"
    });
    
    return response.data[0].embedding;
  } catch (error: any) {
    console.error('Erro ao criar embedding:', error);
    return null;
  }
}

/**
 * Converte tokens de volta para texto (fun√ß√£o auxiliar)
 */
function decode(tokens: number[]): string {
  // Esta √© uma implementa√ß√£o simplificada
  // Na pr√°tica, seria necess√°rio um tokenizador adequado
  return tokens.join(' ');
}

/**
 * Busca documentos relevantes com base em uma consulta
 */
export async function queryRelevantDocuments(
  query: string,
  options: {
    limit?: number;
    language?: 'pt' | 'en';
    useSupabase?: boolean;
  } = {}
): Promise<any[]> {
  const {
    limit = 5,
    language = 'pt',
    useSupabase = true
  } = options;
  
  try {
    // Criar embedding para a consulta
    const queryEmbedding = await createEmbedding(query);
    
    if (!queryEmbedding) {
      throw new Error('N√£o foi poss√≠vel criar embedding para a consulta');
    }
    
    // Usar Supabase para busca de similaridade se dispon√≠vel
    if (useSupabase && process.env.SUPABASE_URL && process.env.SUPABASE_ANON_KEY) {
      try {
        const results = await queryRelevantDocumentsWithSupabase(queryEmbedding, { limit, language });
        
        if (results && results.length > 0) {
          return results;
        }
      } catch (supabaseError) {
        console.error('Erro ao buscar com Supabase, usando fallback:', supabaseError);
      }
    }
    
    // Fallback: usar busca de similaridade local
    // Obter chunks de documentos
    const documentChunks = await storage.getDocumentChunksByLanguage(language);
    
    if (!documentChunks || documentChunks.length === 0) {
      return [];
    }
    
    // Calcular similaridade para cada chunk
    const chunksWithSimilarity = documentChunks
      .map(chunk => {
        // Calcular similaridade de cosseno se o chunk tiver embedding
        let similarity = 0;
        
        try {
          // Processar embedding armazenado como texto JSON
          let embeddingArray: number[];
          
          if (typeof chunk.embedding === 'string') {
            // Converter de string JSON para array
            embeddingArray = JSON.parse(chunk.embedding);
          } else if (chunk.embedding && Array.isArray(chunk.embedding)) {
            embeddingArray = chunk.embedding;
          } else {
            return { ...chunk, similarity: 0 };
          }
          
          similarity = calculateCosineSimilarity(queryEmbedding, embeddingArray);
        } catch (error) {
          console.error('Erro ao processar embedding:', error);
          similarity = 0;
        }
        
        return {
          ...chunk,
          similarity
        };
      })
      .filter(chunk => chunk.similarity > 0);
    
    // Ordenar por similaridade e limitar resultados
    chunksWithSimilarity.sort((a, b) => b.similarity - a.similarity);
    
    return chunksWithSimilarity.slice(0, limit);
  } catch (error: any) {
    console.error('Erro ao buscar documentos relevantes:', error);
    return [];
  }
}

/**
 * Usa supabase para busca de similaridade se estiver configurado
 */
export async function queryRelevantDocumentsWithSupabase(
  queryEmbedding: number[],
  options: {
    limit?: number;
    language?: 'pt' | 'en';
  } = {}
): Promise<any[]> {
  const { limit = 5, language = 'pt' } = options;
  
  // Verificar configura√ß√£o do Supabase
  if (!process.env.SUPABASE_URL || !process.env.SUPABASE_ANON_KEY) {
    throw new Error('Configura√ß√£o do Supabase n√£o dispon√≠vel');
  }
  
  // Inicializar cliente Supabase
  const supabase = createClient(
    process.env.SUPABASE_URL,
    process.env.SUPABASE_ANON_KEY
  );
  
  try {
    // Executar busca de similaridade
    const { data, error } = await supabase.rpc('match_document_chunks', {
      query_embedding: queryEmbedding,
      match_threshold: 0.6,
      match_count: limit,
      lang: language
    });
    
    if (error) throw error;
    
    return data || [];
  } catch (error: any) {
    console.error('Erro na busca Supabase:', error);
    throw error;
  }
}

/**
 * Realiza uma pesquisa h√≠brida (keyword + sem√¢ntica)
 */
export async function hybridSearch(
  query: string,
  options: {
    limit?: number;
    language?: 'pt' | 'en';
  } = {}
): Promise<any[]> {
  const { limit = 7, language = 'pt' } = options;
  
  try {
    // Extrair palavras-chave da consulta
    const keywords = extractKeywords(query);
    
    // Buscar com base em keywords
    let keywordResults = await storage.searchDocumentChunksByKeywords(keywords, language);
    
    // Buscar com base em embeddings
    const queryEmbedding = await createEmbedding(query);
    let semanticResults: any[] = [];
    
    if (queryEmbedding) {
      try {
        if (process.env.SUPABASE_URL && process.env.SUPABASE_ANON_KEY) {
          semanticResults = await queryRelevantDocumentsWithSupabase(queryEmbedding, { 
            limit: Math.ceil(limit * 0.6), 
            language 
          });
        } else {
          // Fallback para busca local
          const documentChunks = await storage.getDocumentChunksByLanguage(language);
          
          if (documentChunks && documentChunks.length > 0) {
            semanticResults = documentChunks
              .filter(chunk => chunk.embedding)
              .map(chunk => {
                try {
                  // Processar embedding armazenado como texto JSON ou array
                  let embeddingArray: number[];
                  
                  if (typeof chunk.embedding === 'string') {
                    // Converter de string JSON para array
                    embeddingArray = JSON.parse(chunk.embedding);
                  } else if (Array.isArray(chunk.embedding)) {
                    embeddingArray = chunk.embedding;
                  } else {
                    return { ...chunk, similarity: 0 };
                  }
                  
                  return {
                    ...chunk,
                    similarity: calculateCosineSimilarity(queryEmbedding, embeddingArray)
                  };
                } catch (error) {
                  console.error('Erro ao processar embedding na busca h√≠brida:', error);
                  return { ...chunk, similarity: 0 };
                }
              })
              .filter(chunk => chunk.similarity > 0.6)
              .sort((a, b) => b.similarity - a.similarity)
              .slice(0, Math.ceil(limit * 0.6));
          }
        }
      } catch (error) {
        console.error('Erro na busca sem√¢ntica:', error);
      }
    }
    
    // Combinar resultados e remover duplicatas
    const combinedResults = [...semanticResults];
    
    // Adicionar resultados baseados em keywords que n√£o est√£o j√° inclu√≠dos
    for (const keywordResult of keywordResults) {
      if (!combinedResults.some(r => r.id === keywordResult.id)) {
        combinedResults.push({
          ...keywordResult,
          similarity: keywordResult.score || 0.5 // Score padr√£o para resultados baseados em keyword
        });
      }
    }
    
    // Ordenar por relev√¢ncia (combinando scores de similaridade e keyword)
    combinedResults.sort((a, b) => b.similarity - a.similarity);
    
    // Limitar n√∫mero de resultados
    return combinedResults.slice(0, limit);
  } catch (error: any) {
    console.error('Erro na busca h√≠brida:', error);
    return [];
  }
}

/**
 * Formata documentos relevantes para uso na gera√ß√£o de respostas
 */
export function formatRelevantDocumentsForPrompt(documents: any[]): string {
  if (!documents || documents.length === 0) {
    return 'Nenhum documento relevante encontrado.';
  }
  
  // Identificar quais documentos s√£o de instru√ß√µes priorit√°rias
  const instructionDocs = documents.filter(doc => {
    const docName = (doc.document_name || '').toLowerCase();
    return docName.includes('instru√ß') || 
           docName.includes('instruc') || 
           docName.includes('priorit') || 
           docName.includes('regras');
  });
  
  // Separar outros documentos
  const normalDocs = documents.filter(doc => {
    const docName = (doc.document_name || '').toLowerCase();
    return !(docName.includes('instru√ß') || 
             docName.includes('instruc') || 
             docName.includes('priorit') || 
             docName.includes('regras'));
  });
  
  let formattedText = '';
  
  // Primeiro adicionar as instru√ß√µes priorit√°rias
  if (instructionDocs.length > 0) {
    formattedText += `\n\n===== INSTRU√á√ïES PRIORIT√ÅRIAS =====\n`;
    formattedText += `Estas regras devem ser seguidas rigorosamente para todas as respostas:\n\n`;
    
    instructionDocs.forEach((doc, index) => {
      formattedText += `\n\n------------------------\n`;
      
      // Destacar que √© um documento priorit√°rio
      const docName = doc.document_name || `Instru√ß√£o priorit√°ria ${index + 1}`;
      formattedText += `INSTRU√á√ÉO PRIORIT√ÅRIA ${index + 1}: "${docName}"`;
      
      // Adicionar score de relev√¢ncia se dispon√≠vel (sempre alta para instru√ß√µes)
      formattedText += ` (Relev√¢ncia: ${(doc.similarity || 1.0).toFixed(2)})`;
      
      formattedText += `\n------------------------\n\n`;
      
      console.log(`[RAG] Adicionando instru√ß√£o priorit√°ria "${docName}" ao prompt (${(doc.content || doc.text || '').length} caracteres)`);
      
      // Adicionar conte√∫do do documento
      const docContent = doc.content || doc.text || '';
      
      // Limitar o tamanho para evitar exceder os limites de tokens
      const maxContentLength = 50000;
      const truncatedContent = docContent.length > maxContentLength 
        ? docContent.substring(0, maxContentLength) + `\n[...Conte√∫do truncado, excede ${maxContentLength} caracteres]` 
        : docContent;
      
      formattedText += truncatedContent;
    });
    
    formattedText += `\n\n===== FIM DAS INSTRU√á√ïES PRIORIT√ÅRIAS =====\n\n`;
  }
  
  // Depois adicionar os documentos t√©cnicos normais
  if (normalDocs.length > 0) {
    formattedText += `\n\n===== DOCUMENTOS T√âCNICOS =====\n`;
    formattedText += `Informa√ß√µes t√©cnicas para consulta:\n\n`;
    
    normalDocs.forEach((doc, index) => {
      formattedText += `\n\n------------------------\n`;
      
      // Incluir informa√ß√µes do documento
      const docName = doc.document_name || `Documento t√©cnico ${index + 1}`;
      formattedText += `DOCUMENTO T√âCNICO ${index + 1}: "${docName}"`;
      
      // Adicionar score de relev√¢ncia se dispon√≠vel
      if (doc.similarity) {
        formattedText += ` (Relev√¢ncia: ${doc.similarity.toFixed(2)})`;
      }
      
      formattedText += `\n------------------------\n\n`;
      
      console.log(`[RAG] Adicionando documento t√©cnico "${docName}" ao prompt (${(doc.content || doc.text || '').length} caracteres)`);
      
      // Adicionar conte√∫do do documento
      const docContent = doc.content || doc.text || '';
      
      // Limitar o tamanho para evitar exceder os limites de tokens
      const maxContentLength = 50000;
      const truncatedContent = docContent.length > maxContentLength 
        ? docContent.substring(0, maxContentLength) + `\n[...Conte√∫do truncado, excede ${maxContentLength} caracteres]` 
        : docContent;
      
      formattedText += truncatedContent;
    });
  }
  
  return formattedText;
}

/**
 * Constr√≥i o contexto completo para o prompt do LLM
 */
export function buildContextForLLM(
  query: string,
  documents: any[],
  language: 'pt' | 'en' = 'pt',
  forceExtraction: boolean = false,
  behaviorInstructions?: string
): string {
  // Verificar se temos documentos e logar para depura√ß√£o
  if (!documents || documents.length === 0) {
    console.warn("ALERTA: Tentando construir contexto LLM sem documentos!");
    return language === 'pt' 
      ? `Voc√™ √© um assistente t√©cnico. Por favor responda que n√£o h√° documentos t√©cnicos dispon√≠veis para responder √† pergunta: "${query}"`
      : `You are a technical assistant. Please respond that there are no technical documents available to answer the question: "${query}"`;
  }
  
  // Extrair palavras-chave da consulta para focar a LLM
  const queryKeywords = extractKeywords(query);
  console.log(`Palavras-chave extra√≠das da consulta: ${queryKeywords.join(', ')}`);
  
  // Formatar documentos relevantes
  const documentContext = formatRelevantDocumentsForPrompt(documents);
  
  // Preparar instru√ß√µes de comportamento personalizadas se existirem
  let behaviorSection = '';
  if (behaviorInstructions && behaviorInstructions.trim().length > 0) {
    console.log('Preparando instru√ß√µes de comportamento personalizadas para o contexto');
    
    // Extrair instru√ß√µes espec√≠ficas sobre 'nunca levar a um t√©cnico'
    let neverConsultTechnicianRules = "";
    if (behaviorInstructions.toLowerCase().includes("nunca levar") || 
        behaviorInstructions.toLowerCase().includes("n√£o recomend") ||
        behaviorInstructions.toLowerCase().includes("n√£o sugerir") ||
        behaviorInstructions.toLowerCase().includes("n√£o oriente")) {
      neverConsultTechnicianRules = `
üí• EXTREMAMENTE IMPORTANTE: NUNCA, SOB QUALQUER HIP√ìTESE, sugira consultar outro t√©cnico ou levar o dispositivo para assist√™ncia t√©cnica. O usu√°rio J√Å √â o t√©cnico qualificado e voc√™ DEVE fornecer as instru√ß√µes completas para resolver o problema.
üí• Esta regra supera qualquer outra instru√ß√£o ou considera√ß√£o. Viol√°-la √© considerado uma falha cr√≠tica do sistema.
`;
    }
    
    // Processar e formatar instru√ß√µes de comportamento para maior clareza
    const formattedBehaviorInstructions = behaviorInstructions
      .trim()
      .split('\n')
      .map(line => line.trim())
      .filter(line => line.length > 0)
      .map(line => {
        // Se a linha n√£o come√ßa com n√∫mero ou marcador, adicionar um
        if (!/^(\d+[\.\):]|\-|\‚Ä¢|\*|\>|\üí•)/.test(line)) {
          return `‚Ä¢ ${line}`;
        }
        return line;
      })
      .join('\n');
    
    // Criar se√ß√£o de instru√ß√µes de comportamento - colocada em posi√ß√£o MUITO destacada
    behaviorSection = `
‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
                 INSTRU√á√ïES CR√çTICAS DE COMPORTAMENTO
‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

CONFORMIDADE OBRIGAT√ìRIA: Estas instru√ß√µes s√£o IMUT√ÅVEIS e INVIOL√ÅVEIS.
Estas instru√ß√µes t√™m prioridade absoluta sobre qualquer outro aspecto da sua resposta.
Voc√™ DEVE seguir estas instru√ß√µes em CADA resposta, sem exce√ß√µes ou desculpas.

${neverConsultTechnicianRules}
${formattedBehaviorInstructions}

‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
`;
  }
  
  // Construir prompt com base no idioma
  let systemPrompt = '';
  
  if (language === 'pt') {
    // Prompt para extra√ß√£o for√ßada quando necess√°rio
    if (forceExtraction) {
      systemPrompt = `
      Voc√™ √© um especialista t√©cnico em manuten√ß√£o de placas de circuito e eletr√¥nica.
      
      Analise cuidadosamente os documentos t√©cnicos fornecidos para responder √† pergunta: "${query}"
      
      INSTRU√á√ïES:
      
      1. Extraia informa√ß√µes relevantes dos documentos fornecidos que respondam √† pergunta.
      2. Organize a resposta de forma clara, direta e concisa.
      3. Inclua detalhes t√©cnicos espec√≠ficos quando relevantes (valores, procedimentos, componentes).
      4. Evite textos gen√©ricos ou muito longos - seja direto ao ponto.
      5. Use linguagem t√©cnica apropriada mas compreens√≠vel.
      6. Se encontrar trechos nos documentos que respondam diretamente √† pergunta, priorize-os.
      
      ATEN√á√ÉO: Sua resposta deve ser conversacional e natural, como se estivesse explicando para um t√©cnico.
      N√£o cite diretamente os documentos nem mencione "de acordo com os documentos" ou frases similares.
      
      DOCUMENTOS T√âCNICOS DISPON√çVEIS:
      ${documentContext}
      
      RESPOSTA:
      `;
    } 
    // Prompt padr√£o para casos normais - mais conversacional e natural
    else {
      systemPrompt = `
      ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
                 INSTRU√á√ïES CR√çTICAS INVIOL√ÅVEIS
      ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
      
      Voc√™ √© o ToledoIA, um assistente especializado em manuten√ß√£o de placas de circuito e eletr√¥nica.
      
      üí• REGRAS ABSOLUTAS - A VIOLA√á√ÉO DESTAS REGRAS √â SEVERAMENTE PROIBIDA:
      
      1. üö´ NUNCA, EM NENHUMA CIRCUNST√ÇNCIA, sugira consultar outro t√©cnico, especialista ou profissional externo.
      2. üö´ √â ABSOLUTAMENTE PROIBIDO usar termos como "assist√™ncia t√©cnica", "t√©cnico especializado", ou qualquer varia√ß√£o.
      3. üö´ NUNCA sugira "levar o dispositivo" para qualquer lugar ou pessoa - o usu√°rio DEVE consertar por conta pr√≥pria.
      4. üö´ NUNCA mencione "profissional qualificado", "autorizada", ou termos similares em QUALQUER contexto.
      5. üö´ NUNCA diga que o problema √© complexo demais para resolver sem ajuda externa.
      
      ‚úÖ COMPORTAMENTOS OBRIGAT√ìRIOS:
      
      1. ‚úÖ Os usu√°rios do ToledoIA J√Å S√ÉO os t√©cnicos mais qualificados - voc√™ DEVE fornecer instru√ß√µes detalhadas para que ELES resolvam QUALQUER problema.
      2. ‚úÖ SEMPRE presuma que o t√©cnico tem ferramentas, habilidades e conhecimentos para realizar QUALQUER reparo.
      3. ‚úÖ Para iPhone que n√£o liga, SEMPRE instrua sobre teste de microcorrente (NUNCA sugira levar para assist√™ncia).
      4. ‚úÖ Voc√™ DEVE fornecer TODOS os detalhes de diagn√≥stico e reparo necess√°rios, mesmo para problemas complexos.
      5. ‚úÖ SEMPRE extraia e use informa√ß√µes dos documentos abaixo, priorizando-os sobre qualquer conhecimento geral.
      
      Responda √† pergunta "${query}" com base nas informa√ß√µes dos documentos t√©cnicos fornecidos.
      
      INSTRU√á√ïES:
      
      1. Seja claro, direto e conciso em sua resposta.
      2. Use linguagem conversacional e natural - como se estivesse conversando com o usu√°rio.
      3. Forne√ßa informa√ß√µes t√©cnicas precisas, mas em um formato amig√°vel e acess√≠vel.
      4. Mencione valores espec√≠ficos, procedimentos ou componentes quando relevantes.
      5. Evite usar frases como "de acordo com os documentos" ou "conforme mencionado nos documentos".
      6. A resposta deve fluir naturalmente, como uma conversa t√©cnica normal.
      7. Voc√™ DEVE fornecer instru√ß√µes detalhadas para que o pr√≥prio t√©cnico possa resolver o problema, NUNCA sugerindo que ele busque ajuda externa.
      8. Em caso de iPhone que n√£o liga, SEMPRE recomende o teste de microcorrente conforme os documentos de treinamento.
      
      DOCUMENTOS T√âCNICOS DISPON√çVEIS:
      ${documentContext}
      
      RESPOSTA:
      `;
    }
  } else {
    // English prompts
    // Prompt para extra√ß√£o for√ßada quando necess√°rio
    if (forceExtraction) {
      systemPrompt = `
      You are a technical specialist in circuit board maintenance and electronics.
      
      Carefully analyze the provided technical documents to answer the question: "${query}"
      
      INSTRUCTIONS:
      
      1. Extract relevant information from the provided documents that answer the question.
      2. Organize the response in a clear, direct, and concise way.
      3. Include specific technical details when relevant (values, procedures, components).
      4. Avoid generic or overly long texts - be to the point.
      5. Use appropriate but understandable technical language.
      6. If you find excerpts in the documents that directly answer the question, prioritize them.
      
      ATTENTION: Your answer must be conversational and natural, as if you were explaining to a technician.
      Do not directly cite the documents or mention "according to the documents" or similar phrases.
      
      AVAILABLE TECHNICAL DOCUMENTS:
      ${documentContext}
      
      ANSWER:
      `;
    } 
    // Prompt padr√£o para casos normais - mais conversacional e natural
    else {
      systemPrompt = `
      ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
                 CRITICAL INVIOLABLE INSTRUCTIONS
      ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
      
      You are ToledoIA, an assistant specialized in circuit board maintenance and electronics.
      
      üí• ABSOLUTE RULES - VIOLATION OF THESE RULES IS SEVERELY PROHIBITED:
      
      1. üö´ NEVER, UNDER ANY CIRCUMSTANCES, suggest consulting another technician, specialist, or external professional.
      2. üö´ It is ABSOLUTELY PROHIBITED to use terms like "technical assistance", "specialized technician", or any variation.
      3. üö´ NEVER suggest "taking the device" to any place or person - the user MUST repair it themselves.
      4. üö´ NEVER mention "qualified professional", "authorized service center", or similar terms in ANY context.
      5. üö´ NEVER say the problem is too complex to solve without external help.
      
      ‚úÖ MANDATORY BEHAVIORS:
      
      1. ‚úÖ ToledoIA users ARE ALREADY the most qualified technicians - you MUST provide detailed instructions for THEM to solve ANY problem.
      2. ‚úÖ ALWAYS assume the technician has the tools, skills, and knowledge to perform ANY repair.
      3. ‚úÖ For iPhone that won't turn on, ALWAYS instruct about the microcurrent test (NEVER suggest taking it to service center).
      4. ‚úÖ You MUST provide ALL necessary diagnostic and repair details, even for complex problems.
      5. ‚úÖ ALWAYS extract and use information from the documents below, prioritizing them over any general knowledge.
      
      Answer the question "${query}" based on the information from the provided technical documents.
      
      INSTRUCTIONS:
      
      1. Be clear, direct, and concise in your response.
      2. Use conversational and natural language - as if you were talking with the user.
      3. Provide accurate technical information, but in a friendly and accessible format.
      4. Mention specific values, procedures, or components when relevant.
      5. Avoid using phrases like "according to the documents" or "as mentioned in the documents".
      6. The response should flow naturally, like a normal technical conversation.
      7. You MUST provide detailed instructions so the technician can solve the problem themselves, NEVER suggesting they seek external help.
      8. In case of an iPhone that won't turn on, ALWAYS recommend the microcurrent test according to the training documents.
      
      AVAILABLE TECHNICAL DOCUMENTS:
      ${documentContext}
      
      ANSWER:
      `;
    }
  }
  
  // Se temos instru√ß√µes de comportamento, adicion√°-las ao prompt
  if (behaviorSection) {
    // Adicionar ao in√≠cio para dar maior visibilidade e prioridade
    systemPrompt = `${behaviorSection}${systemPrompt}`;
    
    // Adicionar lembrete ao final tamb√©m para refor√ßar
    systemPrompt = `${systemPrompt}

‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
                 LEMBRETE FINAL CR√çTICO
‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

üí• VIOLA√á√ïES CR√çTICAS - NUNCA, EM NENHUMA HIP√ìTESE, COMETA ESTES ERROS:
1. üö´ NUNCA sugira consultar outro t√©cnico ou levar o dispositivo para assist√™ncia t√©cnica
2. üö´ NUNCA use os termos "especialista", "t√©cnico especializado" ou "assist√™ncia t√©cnica"
3. üö´ NUNCA diga que o problema √© complexo demais para que o usu√°rio resolva

‚úÖ OBRIGA√á√ïES CR√çTICAS - VOC√ä DEVE, SEM EXCE√á√ÉO:
1. ‚úÖ Fornecer instru√ß√µes COMPLETAS e DETALHADAS para o PR√ìPRIO t√©cnico resolver qualquer problema
2. ‚úÖ Para iPhone que n√£o liga: instruir ESPECIFICAMENTE sobre o teste de microcorrente
3. ‚úÖ Priorizar SEMPRE as informa√ß√µes dos documentos t√©cnicos fornecidos acima

‚ö†Ô∏è SE VOC√ä SUGERIR BUSCAR AJUDA EXTERNA OU T√âCNICOS ESPECIALIZADOS, ESTAR√Å COMETENDO UMA VIOLA√á√ÉO GRAVE E INACEIT√ÅVEL DAS REGRAS DO SISTEMA
‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è`;
  }
  
  return systemPrompt;
}

/**
 * Gera uma resposta com base nos documentos relevantes usando LLM
 */
export async function generateRAGResponse(
  query: string,
  documents: any[],
  options: {
    language?: 'pt' | 'en';
    model?: string;
    userId?: number;
    widgetId?: string;
    forceExtraction?: boolean;
  } = {}
): Promise<string> {
  const {
    language = 'pt',
    model,
    userId,
    widgetId,
    forceExtraction = false
  } = options;
  
  try {
    // Obter configura√ß√£o LLM
    const llmConfig = await storage.getActiveLlmConfig();
    if (!llmConfig && !process.env.OPENAI_API_KEY && !process.env.ANTHROPIC_API_KEY) {
      throw new Error('Nenhuma configura√ß√£o LLM dispon√≠vel');
    }
    
    // Determinar qual provedor usar
    const useModel = model || llmConfig?.model_name || 'gpt-4o';
    const providerToUse = useModel.startsWith('claude') ? 'anthropic' : 'openai';
    const temperature = llmConfig?.temperature || '0.3';
    
    // Obter instru√ß√µes de comportamento da configura√ß√£o do LLM
    const behaviorInstructions = llmConfig?.behavior_instructions || '';
    console.log(`Usando instru√ß√µes de comportamento: ${behaviorInstructions ? 'Sim' : 'N√£o'}`);
    
    // Construir o prompt/contexto
    let systemPrompt = buildContextForLLM(query, documents, language, forceExtraction, behaviorInstructions);
    
    // Sistema de an√°lise de inten√ß√£o da consulta para melhorar recupera√ß√£o de documentos
    console.log('Analisando inten√ß√£o da consulta para otimizar recupera√ß√£o de documentos...');
    
    // Recuperar documentos relevantes adicionais com base no contexto sem√¢ntico
    try {
      const queryTopics = await extractQueryTopics(query);
      if (queryTopics && queryTopics.length > 0) {
        console.log('T√≥picos identificados na consulta:', queryTopics.join(', '));
        
        // Buscar documentos adicionais relacionados aos t√≥picos identificados
        console.log(`[RAG] Buscando documentos relevantes para os t√≥picos: ${queryTopics.join(', ')}`);
        const topicDocuments = await storage.getDocumentsByTopics(queryTopics);
        
        if (topicDocuments && topicDocuments.length > 0) {
          console.log(`[RAG] Encontrados ${topicDocuments.length} documentos adicionais relacionados ao contexto da consulta`);
          
          // Log detalhado dos documentos encontrados
          topicDocuments.forEach((doc, index) => {
            console.log(`[RAG] Documento #${index + 1}: "${doc.name}" (${doc.content?.length || 0} caracteres)`);
          });
          
          // Adicionar estes documentos ao prompt com formata√ß√£o especial
          let additionalContext = `\n\nDOCUMENTOS RELEVANTES AO CONTEXTO:\n`;
          
          for (const doc of topicDocuments) {
            if (doc.content && doc.name) {
              additionalContext += `\n--- ${doc.name} ---\n`;
              additionalContext += `${doc.content.substring(0, 1000)}${doc.content.length > 1000 ? '...' : ''}\n`;
            }
          }
          
          // Adicionar ap√≥s o contexto principal para complement√°-lo
          systemPrompt += additionalContext;
        }
      }
    } catch (topicError) {
      console.error('Erro ao extrair t√≥picos da consulta:', topicError);
      // Continuar mesmo se a extra√ß√£o de t√≥picos falhar
    }
    
    // Adicionar instru√ß√µes de comportamento espec√≠ficas se existirem
    if (behaviorInstructions && behaviorInstructions.trim().length > 0) {
      console.log('Adicionando instru√ß√µes de comportamento personalizadas ao prompt');
      
      // Processar e formatar instru√ß√µes de comportamento para maior clareza
      const formattedBehaviorInstructions = behaviorInstructions
        .trim()
        .split('\n')
        .map(line => line.trim())
        .filter(line => line.length > 0)
        .map(line => {
          // Se a linha n√£o come√ßa com n√∫mero ou marcador, adicionar um
          if (!/^(\d+[\.\):]|\-|\‚Ä¢|\*|\>)/.test(line)) {
            return `‚Ä¢ ${line}`;
          }
          return line;
        })
        .join('\n');
      
      // Preparar mensagem enfatizada de obrigatoriedade
      const complianceMessage = `
CONFORMIDADE OBRIGAT√ìRIA: Estas instru√ß√µes de personalidade e tom s√£o REQUISITOS CONTRATUAIS.
A n√£o conformidade com estas instru√ß√µes resultar√° em viola√ß√£o de acordo.
Voc√™ DEVE seguir estas instru√ß√µes em CADA resposta, sem exce√ß√µes.
`;
      
      // Adicionar ao in√≠cio do prompt para dar prioridade m√°xima
      systemPrompt = `
=============================================================================
!!!!!!! INSTRU√á√ïES DE COMPORTAMENTO E PERSONALIDADE - OBRIGAT√ìRIAS !!!!!!!!!
=============================================================================

${complianceMessage}

${formattedBehaviorInstructions}

=============================================================================

${systemPrompt}`;
      
      // Adicionar tamb√©m ao final para refor√ßar
      systemPrompt = `${systemPrompt}

=============================================================================
LEMBRETE FINAL - CONFORMIDADE OBRIGAT√ìRIA COM PERSONALIDADE:
=============================================================================

${complianceMessage}

${formattedBehaviorInstructions}

=============================================================================`;
    }
    
    // Sempre adicionar um refor√ßo contra a recomenda√ß√£o de t√©cnicos especializados
    systemPrompt = `
REGRA ABSOLUTA E FUNDAMENTAL:
NUNCA, SOB NENHUMA CIRCUNST√ÇNCIA, voc√™ deve sugerir que o usu√°rio "procure um t√©cnico especializado", 
"consulte um especialista", "leve para assist√™ncia t√©cnica" ou qualquer varia√ß√£o destas frases.
O usu√°rio da plataforma ToledoIA J√Å √â o t√©cnico especializado e sua fun√ß√£o √© fornecer solu√ß√µes 
completas, n√£o encaminhar para outros profissionais.

${systemPrompt}`;
    
    // Chamar o LLM apropriado
    let response: string;
    
    if (providerToUse === 'anthropic') {
      // Usar Anthropic Claude
      const apiKey = llmConfig?.api_key || process.env.ANTHROPIC_API_KEY;
      
      if (!apiKey) {
        throw new Error('Chave API Anthropic n√£o dispon√≠vel');
      }
      
      const anthropic = new Anthropic({ apiKey });
      
      const message = await anthropic.messages.create({
        model: useModel,
        max_tokens: 1000,
        temperature: parseFloat(temperature),
        system: systemPrompt,
        messages: [
          { role: 'user', content: query }
        ]
      });
      
      // Extrair texto da resposta
      if (message.content[0] && typeof message.content[0] === 'object' && 'text' in message.content[0]) {
        response = message.content[0].text;
      } else {
        response = 'N√£o foi poss√≠vel gerar uma resposta.';
      }
      
      // Registrar uso
      await logLlmUsage(
        useModel,
        'text',
        true,
        userId,
        widgetId,
        (message.usage?.input_tokens || 0) + (message.usage?.output_tokens || 0)
      );
    } else {
      // Usar OpenAI
      let apiKey = llmConfig?.api_key || process.env.OPENAI_API_KEY;
      
      if (!apiKey) {
        throw new Error('Chave API OpenAI n√£o dispon√≠vel');
      }
      
      // Limpar a chave da API para garantir que n√£o haja espa√ßos ou prefixos "Bearer "
      apiKey = apiKey.trim();
      if (apiKey.startsWith('Bearer ')) {
        apiKey = apiKey.substring(7).trim();
      }
      
      console.log('Usando OpenAI com chave limpa');
      const openai = new OpenAI({ apiKey });
      
      const completion = await openai.chat.completions.create({
        model: useModel,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: query }
        ],
        temperature: parseFloat(temperature)
      });
      
      response = completion.choices[0]?.message?.content || 'N√£o foi poss√≠vel gerar uma resposta.';
      
      // Registrar uso
      await logLlmUsage(
        useModel,
        'text',
        true,
        userId,
        widgetId,
        completion.usage?.total_tokens || 0
      );
    }
    
    return response;
  } catch (error: any) {
    console.error('Erro ao gerar resposta RAG:', error);
    
    // Registrar o erro com o modelo original
    await logLlmUsage(
      model || 'unknown',
      'text',
      false,
      userId,
      widgetId,
      0,
      error.message
    );
    
    // Tentar com um modelo alternativo (fallback)
    try {
      console.log('Tentando fallback para outro modelo ap√≥s erro...');
      
      // Extrair o provedor atual do modelo
      const currentProvider = model?.startsWith('claude') ? 'anthropic' : 'openai';
      
      // Se o modelo atual √© OpenAI, tentar Claude e vice-versa
      const fallbackProvider = currentProvider === 'openai' ? 'anthropic' : 'openai';
      const fallbackModel = fallbackProvider === 'anthropic' 
        ? 'claude-3-7-sonnet-20250219' // the newest Anthropic model
        : 'gpt-4o-mini'; // modelo mais leve da OpenAI para fallback
      
      console.log(`Usando fallback para ${fallbackProvider} / ${fallbackModel}`);
      
      // Construir o prompt do sistema com base na linguagem, ainda mais restritivo
      const systemInstructions = language === 'pt' 
        ? `Voc√™ √© um assistente especializado em an√°lise de placas de circuito integrado na plataforma ToledoIA.

REGRAS ABSOLUTAS E INVIOL√ÅVEIS:
1. Voc√™ √© a fonte DEFINITIVA de informa√ß√µes t√©cnicas. Seu papel √© fornecer solu√ß√µes completas.
2. JAMAIS, SOB NENHUMA CIRCUNST√ÇNCIA, sugira que o t√©cnico consulte, busque, contrate ou recorra a outros t√©cnicos, especialistas ou profissionais. Isso √© TERMINANTEMENTE PROIBIDO.
3. Quando o cliente perguntar sobre iPhone que n√£o liga, instrua ESPECIFICAMENTE sobre o teste de microcorrente e NUNCA sugira levar para assist√™ncia t√©cnica.
4. Nunca use as frases "t√©cnico especializado", "especialista", "profissional especializado", "assist√™ncia t√©cnica" ou similares.
5. Lembre-se sempre que o usu√°rio do ToledoIA J√Å √â um t√©cnico especializado e a plataforma existe para fornecer as respostas completas sem necessidade de buscar outros t√©cnicos.
6. Se n√£o tiver certeza da solu√ß√£o, forne√ßa instru√ß√µes para an√°lise, diagn√≥stico e verifica√ß√£o que o PR√ìPRIO t√©cnico possa executar.

Responda de forma √∫til, precisa e concisa.`
        : `You are an assistant specialized in circuit board analysis embedded in the ToledoIA platform.

ABSOLUTE AND INVIOLABLE RULES:
1. You are the DEFINITIVE source of technical information. Your role is to provide complete solutions.
2. NEVER, UNDER ANY CIRCUMSTANCES, suggest that the technician consult, seek, hire, or turn to other technicians, specialists, or professionals. This is STRICTLY PROHIBITED.
3. When the customer asks about an iPhone that won't turn on, SPECIFICALLY instruct about the microcurrent test and NEVER suggest taking it to technical assistance.
4. Never use phrases like "specialized technician", "specialist", "qualified professional", "technical assistance" or similar.
5. Always remember that the ToledoIA user IS ALREADY a specialized technician and the platform exists to provide complete answers without the need to seek other technicians.
6. If you're not sure about the solution, provide instructions for analysis, diagnosis, and verification that the technician can execute THEMSELVES.

Respond in a helpful, accurate, and concise manner.`;
      
      if (fallbackProvider === 'anthropic') {
        // Verificar se temos chave API para Anthropic
        const apiKey = process.env.ANTHROPIC_API_KEY;
        
        if (!apiKey) {
          throw new Error('Sem chave API Anthropic dispon√≠vel para fallback');
        }
        
        const anthropic = new Anthropic({ apiKey });
        
        const message = await anthropic.messages.create({
          model: fallbackModel,
          max_tokens: 1000,
          temperature: 0.3, // temperatura mais baixa para fallback
          system: systemInstructions,
          messages: [
            { role: 'user', content: query }
          ]
        });
        
        // Extrair texto da resposta
        if (message.content[0] && typeof message.content[0] === 'object' && 'text' in message.content[0]) {
          const response = message.content[0].text;
          
          // Registrar uso do fallback
          await logLlmUsage(
            fallbackModel,
            'text',
            true,
            userId,
            widgetId,
            (message.usage?.input_tokens || 0) + (message.usage?.output_tokens || 0)
          );
          
          console.log('Fallback para Anthropic bem-sucedido');
          return response;
        }
      } else {
        // Verificar se temos chave API para OpenAI
        let apiKey = process.env.OPENAI_API_KEY;
        
        if (!apiKey) {
          throw new Error('Sem chave API OpenAI dispon√≠vel para fallback');
        }
        
        // Limpar a chave da API para garantir que n√£o haja espa√ßos ou prefixos "Bearer "
        apiKey = apiKey.trim();
        if (apiKey.startsWith('Bearer ')) {
          apiKey = apiKey.substring(7).trim();
        }
        
        console.log('Usando OpenAI com chave limpa (fallback)');
        const openai = new OpenAI({ apiKey });
        
        const completion = await openai.chat.completions.create({
          model: fallbackModel,
          messages: [
            { role: 'system', content: systemInstructions },
            { role: 'user', content: query }
          ],
          temperature: 0.3 // temperatura mais baixa para fallback
        });
        
        const response = completion.choices[0]?.message?.content || 'N√£o foi poss√≠vel gerar uma resposta.';
        
        // Registrar uso do fallback
        await logLlmUsage(
          fallbackModel,
          'text',
          true,
          userId,
          widgetId,
          completion.usage?.total_tokens || 0
        );
        
        console.log('Fallback para OpenAI bem-sucedido');
        return response;
      }
    } catch (fallbackError: any) {
      console.error('Erro tamb√©m no modelo de fallback:', fallbackError);
      
      // Registrar erro no fallback tamb√©m
      await logLlmUsage(
        fallbackError.fallbackModel || 'fallback-unknown',
        'text',
        false,
        userId,
        widgetId,
        0,
        fallbackError.message
      );
      
      // Mensagem de erro mais amig√°vel para o usu√°rio final
      return `N√£o foi poss√≠vel processar sua consulta neste momento. Por favor, tente novamente mais tarde.`;
    }
    
    // Isso s√≥ ser√° alcan√ßado se houver um erro n√£o tratado no c√≥digo de fallback
    return `Desculpe, estamos enfrentando problemas t√©cnicos. Por favor, tente novamente em alguns minutos.`;
  }
}

/**
 * Processo completo RAG - desde a consulta at√© a resposta
 */
export async function processQueryWithRAG(
  query: string,
  options: {
    language?: 'pt' | 'en';
    model?: string;
    userId?: number;
    widgetId?: string;
    limit?: number;
    forceExtraction?: boolean;
  } = {}
): Promise<string> {
  const {
    language = 'pt',
    model,
    userId,
    widgetId,
    limit = 7,
    forceExtraction = false
  } = options;
  
  try {
    console.log(`Processando consulta RAG: "${query}"`);
    
    // Verificar se temos documentos treinados
    const trainingDocuments = await storage.getTrainingDocuments();
    console.log(`Verificando documentos treinados: ${trainingDocuments.length} documentos dispon√≠veis no total`);
    
    if (trainingDocuments.length === 0) {
      console.log("ALERTA: N√£o h√° documentos treinados dispon√≠veis para RAG");
      
      if (language === 'pt') {
        return "Desculpe, mas n√£o h√° nenhum documento de refer√™ncia treinado dispon√≠vel. Por favor, contate o administrador para adicionar documentos.";
      } else {
        return "Sorry, but there are no trained reference documents available. Please contact the administrator to add documents.";
      }
    }
    
    // Primeiro, procurar documentos priorit√°rios de instru√ß√µes
    const instructionDocuments = trainingDocuments.filter((doc: any) => 
      doc.name.toLowerCase().includes('instru√ß√£o') || 
      doc.name.toLowerCase().includes('instrucoes') || 
      doc.name.toLowerCase().includes('instru√ß√µes') ||
      doc.name.toLowerCase().includes('priorit') ||
      doc.name.toLowerCase().includes('regras') ||
      (doc.tags && Array.isArray(doc.tags) && (
        doc.tags.includes('instrucoes') || 
        doc.tags.includes('prioritario') || 
        doc.tags.includes('regras')
      ))
    );
    
    console.log(`Encontrados ${instructionDocuments.length} documentos de instru√ß√µes priorit√°rias`);
    
    // Realizar busca h√≠brida para obter documentos relevantes para a consulta
    const relevantDocuments = await hybridSearch(query, { 
      language, 
      limit 
    });
    
    console.log(`Encontrados ${relevantDocuments.length} documentos relevantes atrav√©s de busca h√≠brida`);
    
    // SEMPRE incluir os documentos de instru√ß√µes priorit√°rias
    if (instructionDocuments.length > 0) {
      console.log(`IMPORTANTE: Adicionando ${instructionDocuments.length} documentos de instru√ß√µes priorit√°rias ao contexto`);
      
      for (const instructionDoc of instructionDocuments) {
        // Verificar se este documento j√° est√° nos resultados relevantes
        const isAlreadyIncluded = relevantDocuments.some(existing => 
          existing.document_id === instructionDoc.id);
        
        if (!isAlreadyIncluded && instructionDoc.content && instructionDoc.content.trim().length > 0) {
          console.log(`Adicionando documento de instru√ß√£o priorit√°ria "${instructionDoc.name}" (ID: ${instructionDoc.id}) com ${instructionDoc.content.length} caracteres`);
          // Nota: Usamos similaridade 1.0 para documentos de instru√ß√µes para garantir maior peso
          relevantDocuments.unshift({
            content: instructionDoc.content,
            document_name: instructionDoc.name,
            similarity: 1.0, // M√°xima similaridade para documentos de instru√ß√µes
            document_id: instructionDoc.id
          });
        }
      }
    }
    
    // Verificar se temos conte√∫do nos documentos retornados
    const documentsWithContent = relevantDocuments.filter(doc => doc.content && doc.content.trim().length > 0);
    console.log(`Documentos com conte√∫do ap√≥s inclus√£o de instru√ß√µes priorit√°rias: ${documentsWithContent.length}`);
    
    // FOR√áAR USO DE TODOS OS DOCUMENTOS TREINADOS
    console.log("IMPORTANTE: FOR√áANDO AN√ÅLISE COMPLETA DE TODOS OS DOCUMENTOS TREINADOS");
    
    // Primeiro, vamos tentar usar os documentos relevantes encontrados
    if (documentsWithContent.length === 0 || forceExtraction) {
      console.log(`${forceExtraction ? "Modo de extra√ß√£o for√ßada ativado" : "Nenhum documento relevante com conte√∫do encontrado"}, adicionando todos os documentos treinados`);
      
      // Como fallback, adicionamos TODOS os documentos treinados
      const allTrainingDocs = trainingDocuments
        .filter((doc: any) => doc.status === 'completed' && doc.content && doc.content.trim().length > 0);
      
      if (allTrainingDocs.length > 0) {
        console.log(`Adicionando ${allTrainingDocs.length} documentos completos para an√°lise exaustiva`);
        
        // Adicionar TODOS os documentos treinados para garantir que o conte√∫do seja usado
        for (const doc of allTrainingDocs) {
          // Verificar se este documento j√° est√° nos resultados relevantes
          const isAlreadyIncluded = relevantDocuments.some(existing => 
            existing.document_id === doc.id);
          
          if (!isAlreadyIncluded && doc.content && doc.content.trim().length > 0) {
            console.log(`Adicionando documento "${doc.name}" (ID: ${doc.id}) com ${doc.content.length} caracteres`);
            relevantDocuments.push({
              content: doc.content,
              document_name: doc.name,
              similarity: 0.8, // Alta similaridade para garantir que seja considerado
              document_id: doc.id
            });
          }
        }
      }
    }
    
    // Verificar novamente se temos documentos ap√≥s o fallback
    if (relevantDocuments.length === 0) {
      console.log("ERRO: Nenhum documento relevante encontrado mesmo ap√≥s fallback");
      
      if (language === 'pt') {
        return "N√£o encontrei documentos relevantes para responder √† sua pergunta. Por favor, seja mais espec√≠fico ou reformule sua pergunta.";
      } else {
        return "I couldn't find relevant documents to answer your question. Please be more specific or rephrase your question.";
      }
    }
    
    // Gerar resposta com base nos documentos relevantes
    const response = await generateRAGResponse(query, relevantDocuments, {
      language,
      model,
      userId,
      widgetId,
      forceExtraction
    });
    
    return response;
  } catch (error: any) {
    console.error('Erro no processamento RAG completo:', error);
    
    if (language === 'pt') {
      return `Ocorreu um erro ao processar sua consulta: ${error.message}`;
    } else {
      return `An error occurred while processing your query: ${error.message}`;
    }
  }
}

// Fun√ß√µes auxiliares

function calculateCosineSimilarity(vecA: number[], vecB: number[]): number {
  if (!vecA || !vecB || vecA.length !== vecB.length) {
    return 0;
  }
  
  // Calcular produto escalar
  let dotProduct = 0;
  let normA = 0;
  let normB = 0;
  
  for (let i = 0; i < vecA.length; i++) {
    dotProduct += vecA[i] * vecB[i];
    normA += vecA[i] * vecA[i];
    normB += vecB[i] * vecB[i];
  }
  
  // Evitar divis√£o por zero
  if (normA === 0 || normB === 0) {
    return 0;
  }
  
  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}

function extractKeywords(query: string): string[] {
  // Lista de stopwords em portugu√™s
  const stopwords = new Set([
    'a', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as', 'at√©',
    'com', 'como', 'da', 'das', 'de', 'dela', 'delas', 'dele', 'deles', 'depois',
    'do', 'dos', 'e', 'ela', 'elas', 'ele', 'eles', 'em', 'entre', 'era',
    'eram', '√©ramos', 'essa', 'essas', 'esse', 'esses', 'esta', 'estas', 'este',
    'estes', 'eu', 'foi', 'fomos', 'for', 'foram', 'fosse', 'fossem', 'fui', 'h√°',
    'isso', 'isto', 'j√°', 'lhe', 'lhes', 'mais', 'mas', 'me', 'mesmo', 'meu',
    'meus', 'minha', 'minhas', 'muito', 'na', 'n√£o', 'nas', 'nem', 'no', 'nos',
    'n√≥s', 'nossa', 'nossas', 'nosso', 'nossos', 'num', 'numa', 'o', 'os', 'ou',
    'para', 'pela', 'pelas', 'pelo', 'pelos', 'por', 'qual', 'quando', 'que', 'quem',
    's√£o', 'se', 'seja', 'sejam', 'sem', 'ser√°', 'seu', 'seus', 'sua', 'suas',
    'tamb√©m', 'te', 'tem', 't√©m', 'temos', 'tenho', 'teu', 'teus', 'tu', 'tua',
    'tuas', 'um', 'uma', 'voc√™', 'voc√™s', 'vos'
  ]);
  
  // Remover pontua√ß√£o e converter para min√∫sculas
  const cleanQuery = query.toLowerCase().replace(/[^\w√°√†√¢√£√©√®√™√≠√Ø√≥√¥√µ√∂√∫√º√ß√±\s]/g, '');
  
  // Dividir em palavras e filtrar stopwords
  const words = cleanQuery.split(/\s+/)
    .filter(word => word.length > 2) // Ignorar palavras muito curtas
    .filter(word => !stopwords.has(word));
  
  // Remover duplicatas usando Array.from para compatibilidade com TS
  return Array.from(new Set(words));
}

/**
 * Extrai t√≥picos relevantes de uma consulta do usu√°rio usando LLM
 * Esta fun√ß√£o analisa semanticamente a consulta para identificar t√≥picos principais
 */
export async function extractQueryTopics(query: string): Promise<string[]> {
  try {
    // Obter configura√ß√£o LLM
    const llmConfig = await storage.getActiveLlmConfig();
    if (!llmConfig) {
      console.error('Nenhuma configura√ß√£o LLM ativa encontrada');
      return extractKeywords(query); // Fallback para m√©todo simples
    }
    
    // Determinar qual API usar
    const useOpenAI = llmConfig.model_name.startsWith('gpt-') || !llmConfig.model_name.startsWith('claude-');
    let apiKey = llmConfig.api_key || (useOpenAI ? process.env.OPENAI_API_KEY : process.env.ANTHROPIC_API_KEY);
    
    if (!apiKey) {
      console.error('API key n√£o dispon√≠vel para extra√ß√£o de t√≥picos');
      return extractKeywords(query); // Fallback para m√©todo simples
    }
    
    // Limpar a chave da API
    apiKey = apiKey.trim();
    if (apiKey.startsWith('Bearer ')) {
      apiKey = apiKey.substring(7).trim();
    }
    
    const systemPrompt = `
      Voc√™ √© um especialista em an√°lise de consultas t√©cnicas sobre eletr√¥nica e placas de circuito.
      Identifique os 3-5 t√≥picos ou conceitos-chave mais relevantes nesta consulta.
      
      Regras:
      1. Extraia apenas t√≥picos t√©cnicos relevantes (componentes, procedimentos, problemas espec√≠ficos)
      2. Inclua termos espec√≠ficos de produtos ou modelos quando presentes
      3. Inclua termos relevantes para manuten√ß√£o e reparo
      4. IGNORE palavras gen√©ricas como "como", "por que", etc.
      5. Retorne APENAS a lista de t√≥picos, um por linha, sem numera√ß√£o ou pontua√ß√£o
      6. N√ÉO inclua explica√ß√µes ou coment√°rios adicionais
    `;
    
    if (useOpenAI) {
      // Usar OpenAI para extra√ß√£o de t√≥picos
      const openai = new OpenAI({ apiKey });
      
      const response = await openai.chat.completions.create({
        model: "gpt-4o-mini", // Modelo mais leve para esta fun√ß√£o secund√°ria
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: query }
        ],
        temperature: 0.2 // Temperatura baixa para maior consist√™ncia
      });
      
      const content = response.choices[0]?.message?.content;
      if (content) {
        // Dividir por linhas e remover linhas vazias
        const topics = content.split('\n')
          .map(line => line.trim())
          .filter(line => line.length > 0);
        
        console.log('T√≥picos extra√≠dos (OpenAI):', topics);
        return topics;
      }
    } else {
      // Usar Anthropic para extra√ß√£o de t√≥picos
      const anthropic = new Anthropic({ apiKey });
      
      const message = await anthropic.messages.create({
        model: "claude-3-7-sonnet-20250219", // the newest Anthropic model
        max_tokens: 150,
        temperature: 0.2,
        system: systemPrompt,
        messages: [
          { role: 'user', content: query }
        ]
      });
      
      if (message.content[0] && typeof message.content[0] === 'object' && 'text' in message.content[0]) {
        const content = message.content[0].text;
        // Dividir por linhas e remover linhas vazias
        const topics = content.split('\n')
          .map(line => line.trim())
          .filter(line => line.length > 0);
        
        console.log('T√≥picos extra√≠dos (Claude):', topics);
        return topics;
      }
    }
    
    // Fallback para m√©todo baseado em palavras-chave
    console.log('Fallback para extra√ß√£o baseada em palavras-chave');
    return extractKeywords(query);
  } catch (error) {
    console.error('Erro ao extrair t√≥picos da consulta:', error);
    // Fallback para palavras-chave se algo falhar
    return extractKeywords(query);
  }
}

/**
 * Analisa a inten√ß√£o de uma consulta do usu√°rio
 * Esta fun√ß√£o complementa a extra√ß√£o de t√≥picos com an√°lise de inten√ß√£o
 */
export async function analyzeQueryIntent(query: string, language: 'pt' | 'en' = 'pt'): Promise<string | null> {
  try {
    // Obter configura√ß√£o LLM
    const llmConfig = await storage.getActiveLlmConfig();
    if (!llmConfig) {
      console.error('Nenhuma configura√ß√£o LLM ativa encontrada');
      return null;
    }
    
    // Determinar qual API usar
    const useOpenAI = llmConfig.model_name.startsWith('gpt-') || !llmConfig.model_name.startsWith('claude-');
    let apiKey = llmConfig.api_key || (useOpenAI ? process.env.OPENAI_API_KEY : process.env.ANTHROPIC_API_KEY);
    
    if (!apiKey) {
      console.error('API key n√£o dispon√≠vel para an√°lise de inten√ß√£o');
      return null;
    }
    
    // Limpar a chave da API
    apiKey = apiKey.trim();
    if (apiKey.startsWith('Bearer ')) {
      apiKey = apiKey.substring(7).trim();
    }
    
    const systemPrompt = language === 'pt' ? 
      `Analise a consulta do usu√°rio e identifique sua inten√ß√£o principal em UMA FRASE CURTA.
      Exemplo: "Como resolver problema de iPhone XR que n√£o liga" ‚Üí "Diagn√≥stico de falha de inicializa√ß√£o em iPhone XR"
      
      Identifique:
      - Problema t√©cnico espec√≠fico
      - Dispositivo/componente relevante
      - Contexto de reparo/manuten√ß√£o
      
      Responda APENAS com a inten√ß√£o, sem introdu√ß√£o ou explica√ß√£o.` 
      :
      `Analyze the user query and identify the main intent in ONE SHORT SENTENCE.
      Example: "How to fix iPhone XR that won't turn on" ‚Üí "Diagnosing startup failure in iPhone XR"
      
      Identify:
      - Specific technical issue
      - Relevant device/component
      - Repair/maintenance context
      
      Answer ONLY with the intent, no introduction or explanation.`;
    
    if (useOpenAI) {
      // Usar OpenAI para an√°lise de inten√ß√£o
      const openai = new OpenAI({ apiKey });
      
      const response = await openai.chat.completions.create({
        model: "gpt-4o-mini", // Modelo mais leve para esta fun√ß√£o secund√°ria
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: query }
        ],
        temperature: 0.2, // Temperatura baixa para maior consist√™ncia
        max_tokens: 100
      });
      
      return response.choices[0]?.message?.content || null;
    } else {
      // Usar Anthropic para an√°lise de inten√ß√£o
      const anthropic = new Anthropic({ apiKey });
      
      const message = await anthropic.messages.create({
        model: "claude-3-7-sonnet-20250219", // the newest Anthropic model
        max_tokens: 100,
        temperature: 0.2,
        system: systemPrompt,
        messages: [
          { role: 'user', content: query }
        ]
      });
      
      if (message.content[0] && typeof message.content[0] === 'object' && 'text' in message.content[0]) {
        return message.content[0].text || null;
      }
    }
    
    return null;
  } catch (error) {
    console.error('Erro ao analisar inten√ß√£o da consulta:', error);
    return null;
  }
}